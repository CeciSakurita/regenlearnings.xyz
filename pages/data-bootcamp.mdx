# Regen Data Bootcamp

This is a WIP curriculum for a regen data bootcamp. We know everyone is very busy, so we want to design something which is very easy to manage, requires little time commitment, and taps people‚Äôs intrinsic motivation to learn on their own. We take inspiration from https://speedrunethereum.com/ - the learners help build the next content for the course! Most learning will be async.
<br>
<a
  href="https://lu.ma/event/evt-OKMLvmtOr8ph67v"
  class="luma-checkout--button"
  data-luma-action="checkout"
  data-luma-event-id="evt-OKMLvmtOr8ph67v"
>
  <strong>Register for the Data Bootcamp Intro Call</strong>
</a>

## Objectives

We are starting with the intro level ("Panda"). We did a poll and more than half of the people who participated (18/33) said this was the level they were interested in. Therefore, the goal is to help people go from 0 to 1. Ideally we can get a cohort of 7-12 people to learn some fresh skills and then they can join up with a more advanced cohort ("Foxes" or "Cheetahs") in a few months. 

### üêº Panda Level
I want to start at the beginning. I know how to write formulas in Google Sheets and Notion databases, but I am new or extremely rusty at Python. I want to learn the basics of loading, transforming & visualizing data. I want to learn the basics of reading blockchain data via a blockexplorer, and querying that data with basic SQL queries. By the end of this course, I should be able to fire up a Jupyter Notebook, load a CSV file, run some functions on the data, and make a pretty chart.

Topics will cover:
- Discussing the meaning of Impact Data Science
- Setting up an easy coding environment on your computer
- Python fundamentals (variables, data structures, functions)
- Loading dataframes from CSV files
- Exploratory data analysis in Pandas
- Reading a block explorer/understanding transactions 
- Forming basic SQL queries
- Making not beautiful charts

## Future Levels

We will try to continue if we have success at the Panda Level.

### ü¶ä Fox Level
I want more data. I know how to work with dataframes, but my issue is extracting and cleaning data from different sources. I want to learn how to work with APIs, write crawlers, and join data that comes from different sources on the internet. By the end of this course, I should be able to write a GraphQL query to fetch data from Ethereum Attestation Service, normalize blobs of metadata, and ping the Etherscan API to get additional info about each attestation. 

Topics will cover:
- Working with popular web3 APIs (Dune, Flipside, Covalent)
- Making requests and getting data back
- Writing scripts that can index data from multiple sources
- Logging and error handling (sorry, but shit will break a lot)
- Getting ChatGPT to write SQL / GraphQL for you

### üêÜ Cheetah Level
I want to share insights. I know how to get and process data, but I want to make beautiful charts and interactive data visualizations. I want to learn the different charts and visualization libraries, and I want control over every little styling detail. By the end of this course, I should be able to make an interactive Sankey diagram with Plotly, a beautiful heatmap with Datashader, a scatter plot with Seaborn, and a lightweight web app with Streamlit. 

Topics will cover:
- Make beautiful charts
- Getting the small stuff right when it comes to styling
- Working with Python charting libraries
- Learning enough JavaScript and html/CSS to be a minor threat
- Deploying data apps and charting widgets
- Storytelling with data
